{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  Multinomial responses - simulations\n",
    "\n",
    "### Econometrics B (Ã˜kB)\n",
    "\n",
    "(Wooldridge Ch. 16)\n",
    "\n",
    "Bertel Schjerning\n",
    "\n",
    "Department of Economics, University of Copenhagen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# routines for simulation and estimation of conditional logit\n",
    "from discrete_choice import *  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulate data and estimate conditional logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional logit\n",
      "Initial log-likelihood -1.6094379124340998\n",
      "Initial gradient\n",
      " [0.81902622 0.09739716 1.16919721]\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac\n",
      "----------  -----------  ----------  ----------  ----------\n",
      "var0            0.99353     0.01486    66.85495    -0.00001\n",
      "var1           -1.01147     0.01814   -55.74979     0.00000\n",
      "var2            2.00958     0.02739    73.35655     0.00001\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -6636.285095894722 \n",
      "\n",
      "Iteration info: 11 iterations, 12 evaluations of objective, and 12 evaluations of gradients\n",
      "Elapsed time: 0.1219 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "J=5             # number of alternatives index j=0,..,J-1\n",
    "N=10000         # number of observations\n",
    "theta=np.array([1, -1, 2]).reshape(-1,1)  # True parameters\n",
    "dta=sim_data(N, J, theta);\n",
    "res=clogit(dta['y'], dta['x'], deriv=1)  # Estimate c-logit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute derivatives of conditional Logit\n",
    "\n",
    "Marginal effects wrt alternative-specific covariates $x_{ik}$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial x_{ik}}P({y_i=j \\mid x_i})\n",
    "\\quad=\\quad p_{ij}\\left(\\mathbb{1}(k=j)-p_{ik}\\right)\\beta$$\n",
    "\n",
    "Below we compute derivatives averaged over the sample, i.e. average partial effects (APE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "APE wrt change in var0\n",
      "              p0          p1          p2          p3          p4\n",
      "----  ----------  ----------  ----------  ----------  ----------\n",
      "alt0     0.02968    -0.00352    -0.00592    -0.00850    -0.01174\n",
      "alt1    -0.00352     0.04708    -0.00948    -0.01433    -0.01975\n",
      "alt2    -0.00592    -0.00948     0.07102    -0.02336    -0.03226\n",
      "alt3    -0.00850    -0.01433    -0.02336     0.09543    -0.04924\n",
      "alt4    -0.01174    -0.01975    -0.03226    -0.04924     0.11300\n",
      "\n",
      "ckeck: derivatibes should sum to 0 over all alterntives \n",
      " [ 1.73472348e-18  6.93889390e-18  0.00000000e+00 -6.93889390e-18\n",
      " -1.38777878e-17]\n"
     ]
    }
   ],
   "source": [
    "def APE_var(theta, x, m=0, quiet=False): \n",
    "    # matrix of partial derivatibes with respect ot a change in attribute m\n",
    "    N, J, K, palt, xalt, xvars = labels(x)\n",
    "    p=ccp(utiliy(theta, x))\n",
    "    E=np.empty((J,J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            E[k, j]=np.mean(p[:,j]*theta[m]*(1*(j==k)-p[:,k]), axis=0)\n",
    "    if not quiet: \n",
    "        print('\\nAPE wrt change in', xvars[m])\n",
    "        print(tabulate(np.c_[xalt, E], headers=palt,floatfmt=\"10.5f\"))\n",
    "    return E\n",
    "\n",
    "dydx=APE_var(res.theta_hat, dta['x'], m=0)\n",
    "print('\\nckeck: derivatibes should sum to 0 over all alterntives \\n', np.sum(dydx,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compute elasticities\n",
    "- The elasticity of $p_{ij}$ wrt to a change alternative-specific attribute $x_{ik}$ is\n",
    "\n",
    "$$E_{j, x_{ik}}= \\frac{x_{ik}}{p_{ij}}\\frac{\\partial p_{ij}}{\\partial x_{ik}}\n",
    "\\quad=\\quad \\frac{x_{ik}}{p_{ij}}  p_{ij}\\left(\\mathbb{1}(k=j)-p_{ik}\\right)\\beta \n",
    "\\quad=\\quad \\left(\\mathbb{1}(k=j)-p_{ik}\\right) x_{ik}\\beta $$\n",
    "- **Own elasticity** (i.e. when $k=j$)\n",
    "\n",
    "$$E_{j, x_{ik}}= \n",
    "\\quad=\\quad (1-p_{ik})x_{ik}\\beta $$\n",
    "\n",
    "- **The cross-price elasticity** (i.e. when $k\\ne j$) is completely independent of $j$ (due to IIA)\n",
    "\n",
    "$$E_{j, x_{ik}}= \n",
    "\\quad=\\quad -p_{ik} x_{ik}\\beta $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Ematrix_var(theta, x, m=1, quiet=False):\n",
    "    # matrix of elasticities with respect ot a change in attribute m\n",
    "    N, J, K, palt, xalt, xvars = labels(x)\n",
    "    p=ccp(utiliy(theta, x))\n",
    "    E=np.empty((J,J))\n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            E[k, j]=np.mean(x[:,k,m]*theta[m]*(1*(j==k)-p[:,k]), axis=0)\n",
    "    if not quiet: \n",
    "        print('\\nElasticity wrt change in', xvars[m])\n",
    "        print(tabulate(np.c_[xalt, E], headers=palt,floatfmt=\"10.5f\"))\n",
    "    return E\n",
    "E=Ematrix_var(res.theta_hat, dta['x'], m=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Ematrix_own(theta, x, quiet=False):\n",
    "    # Own elasticity: % change in prob of altertive j wrt % change in attribute of same alternative j\n",
    "    # done for for each varible in x  \n",
    "    N, J, K, palt, xalt, xvars = labels(x)\n",
    "    p=ccp(utiliy(theta, x))\n",
    "    E_own=np.empty((J, K))\n",
    "    for iJ in range(J):\n",
    "        for iK in range(K):\n",
    "            E_own[iJ, iK]=np.mean(x[:,iJ,iK]*theta[iK]*(1-p[:,iJ]), axis=0)\n",
    "    if not quiet: \n",
    "        print('\\nOwn elasticity')\n",
    "        print(tabulate(np.c_[xalt, E_own], headers=xvars,floatfmt=\"10.5f\"))\n",
    "    return E_own\n",
    "\n",
    "E=Ematrix_own(res.theta_hat, dta['x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Ematrix_cross(theta, x, quiet=False):\n",
    "    # Cross elasticity:  % change in prob of altertive j wrt % change in attribute of other alternative k ne j\n",
    "    # done for each varible in x  \n",
    "    N, J, K, palt, xalt, xvars = labels(x)\n",
    "    p=ccp(utiliy(theta, x))\n",
    "    E_cross=np.empty((J, K))\n",
    "    for iJ in range(J):\n",
    "        for iK in range(K):\n",
    "            E_cross[iJ, iK]=np.mean(x[:,iJ,iK]*theta[iK]*(-p[:,iJ]), axis=0)\n",
    "    if not quiet: \n",
    "        print('\\nCross-Elasticity')\n",
    "        print(tabulate(np.c_[xalt, E_cross], headers=xvars,floatfmt=\"10.5f\"))\n",
    "    \n",
    "E=Ematrix_cross(res.theta_hat, dta['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# MAKE NEW SIMULATION, ESTIMATE AND COMPARE OUTPUT\n",
    "theta=np.array([1, 2]).reshape(-1,1)*1\n",
    "K= theta.shape[0]\n",
    "N=1000\n",
    "J=3\n",
    "dta=sim_data(N, J, theta) \n",
    "res=clogit(dta['y'], dta['x'], deriv=1, quiet=False)\n",
    "\n",
    "for m in range(K): \n",
    "    E=Ematrix_var(res.theta_hat, dta['x'], m=0)\n",
    "E=Ematrix_own(res.theta_hat, dta['x'])\n",
    "E=Ematrix_cross(res.theta_hat, dta['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monte Carlo Experiment\n",
    "Analysis of properties of MLE estimator for conditional logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# MONTECARLO\n",
    "\n",
    "# Parameters for experimental design\n",
    "theta=np.array([1, 2]).reshape(-1,1)*1\n",
    "K= theta.shape[0]\n",
    "N=1000\n",
    "J=10 \n",
    "nM=500 # number of monte carlo samples\n",
    "\n",
    "# run experiments\n",
    "for iM in range(nM): \n",
    "    dta=sim_data(N, J, theta) # simulate data - make sure seed is not fixed\n",
    "    res_im=clogit(dta['y'], dta['x'], deriv=1, quiet=True) # etstimate model and save results\n",
    "    if iM==0: \n",
    "        res=res_im  # initialize results dict\n",
    "    res[iM]=res_im  # save results for each iM \n",
    "print('Monte Carlo done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Compile results and print summary output\n",
    "# Does theta_hat and se seem to be unbiased estimators for theta and the standard error? \n",
    "MC_theta=np.empty((nM,K))\n",
    "MC_se=np.empty((nM,K))\n",
    "for iM in range(nM): \n",
    "    MC_theta[iM,:]=res[iM].theta_hat.T\n",
    "    MC_se[iM,:]=res[iM].se.T\n",
    "\n",
    "print('E(theta_true):\\n'       , theta.T)\n",
    "print('E(theta_hat):\\n'       , np.mean(MC_theta, 0))\n",
    "print('E(theta_hat-theta_true):\\n' , np.mean(MC_theta, 0)-theta.T)\n",
    "print('Monte Carlo Standard Devivation, std(theta_hat):\\n'       , np.std(MC_theta, 0))\n",
    "print('E(se):\\n' , np.mean(MC_se, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot montecarlo distribution theta_hat\n",
    "# Does distribution look approximately normal as theory would predict?\n",
    "for i in range(K):\n",
    "    plt.title('parameter estimates')\n",
    "    plt.hist(MC_theta[:,i], bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot montecarlo distribution of test for hypothesis that theta_hat=theta\n",
    "# Does distribution look approximately standard normal as theory would predict?\n",
    "for i in range(K):\n",
    "    plt.title('(theta_hat[%d]-theta[%d])/se[%d]:' % (i,i,i))\n",
    "    plt.hist((MC_theta[:,i]-theta[i])/MC_se[:,i], bins = 50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other things to try out in Monte Carlo\n",
    "- What happens as $N$ go to infinity\n",
    "    - Can you verify that the MLE estimator $\\hat{\\theta}$ is $\\sqrt(N)$-consistent for $\\theta$\n",
    "    - You may want run a sequence of experiments for different values of N and plot mean and standard derivation of $\\sqrt{N}(\\hat{\\theta}-\\theta)$ against $N$\n",
    "    -  What happens if you do not multiply with $\\sqrt{N}$\n",
    "    \n",
    "- What happens as $J$ increase (will standard error increase or fall)\n",
    "\n",
    "- What about the distribution of other statistics (elasticities, derivatives, etc)\n",
    "\n",
    "- What happens if logit is misspecified\n",
    "    - neglegted heterogeneity\n",
    "    - correlation accross alterntives\n",
    "    - what can you estimate (parameters, elasticities, derivatives, etc)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "date": 1602643870.398518,
  "filename": "38_optimization.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "title": "Econometrics B #13"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
